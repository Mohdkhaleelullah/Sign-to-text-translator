# Sign-to-text-translator
This project converts real-time sign language gestures into readable text and speech using computer vision and deep learning. It uses a webcam to detect hand gestures, classifies them into alphabets or words, and provides spoken feedback using text-to-speech. Built with TensorFlow, OpenCV, MediaPipe, and CVZone.
